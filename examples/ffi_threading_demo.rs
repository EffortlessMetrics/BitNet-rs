//! FFI Threading Utilities Demonstration
//!
//! This example demonstrates the enhanced FFI threading utilities introduced
//! in PR #179, showcasing robust threading patterns and error handling.
//!
//! Key features demonstrated:
//! - Bounded channel architecture preventing resource exhaustion
//! - RAII job tracking preventing counter desynchronization
//! - Thread-safe error handling and propagation
//! - Configurable thread pool management
//! - Graceful shutdown and cleanup

// Note: This is a demonstration example showing the FFI threading concepts
// In a real application, you would use the bitnet-ffi crate directly
// For now, we'll demonstrate the concepts using mock structures

use std::collections::HashMap;
use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, Ordering};
use std::thread;
use std::time::Duration;

// Mock structures to demonstrate the threading concepts from PR #179
pub struct ThreadPoolConfig {
    pub num_threads: usize,
    pub max_queue_size: usize,
    pub stack_size: Option<usize>,
    pub thread_name_prefix: String,
}

#[derive(Debug)]
pub struct BitNetCError(String);

impl std::fmt::Display for BitNetCError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.0)
    }
}

impl std::error::Error for BitNetCError {}

impl Default for ThreadPoolConfig {
    fn default() -> Self {
        Self {
            num_threads: 4, // Mock: use fixed number instead of num_cpus::get()
            max_queue_size: 1000,
            stack_size: None,
            thread_name_prefix: "bitnet-worker".to_string(),
        }
    }
}

pub struct ThreadManager {
    active_jobs: Arc<AtomicUsize>,
    config: ThreadPoolConfig,
}

impl Default for ThreadManager {
    fn default() -> Self {
        Self::new()
    }
}

impl ThreadManager {
    pub fn new() -> Self {
        Self { active_jobs: Arc::new(AtomicUsize::new(0)), config: ThreadPoolConfig::default() }
    }

    pub fn set_num_threads(&mut self, num_threads: usize) -> Result<(), BitNetCError> {
        self.config.num_threads = num_threads;
        Ok(())
    }

    pub fn initialize(&self) -> Result<(), BitNetCError> {
        println!("   ‚Üí Mock thread manager initialized with {} threads", self.config.num_threads);
        Ok(())
    }

    pub fn execute<F>(&self, job: F) -> Result<(), BitNetCError>
    where
        F: FnOnce() + Send + 'static,
    {
        self.active_jobs.fetch_add(1, Ordering::SeqCst);

        // In real implementation, this would use a bounded channel
        let active_jobs = Arc::clone(&self.active_jobs);
        thread::spawn(move || {
            job();
            active_jobs.fetch_sub(1, Ordering::SeqCst);
        });

        Ok(())
    }

    pub fn wait_for_completion(&self) -> Result<(), BitNetCError> {
        while self.active_jobs.load(Ordering::SeqCst) > 0 {
            thread::sleep(Duration::from_millis(10));
        }
        Ok(())
    }

    pub fn get_stats(&self) -> Result<ThreadPoolStats, BitNetCError> {
        Ok(ThreadPoolStats {
            num_threads: self.config.num_threads,
            active_jobs: self.active_jobs.load(Ordering::SeqCst),
            max_queue_size: self.config.max_queue_size,
        })
    }

    pub fn cleanup(&self) -> Result<(), BitNetCError> {
        println!("   ‚Üí Mock cleanup completed");
        Ok(())
    }
}

pub struct ThreadPoolStats {
    pub num_threads: usize,
    pub active_jobs: usize,
    pub max_queue_size: usize,
}

pub struct ThreadSafeRefCounter<T> {
    data: Arc<std::sync::RwLock<T>>,
    ref_count: Arc<AtomicUsize>,
}

impl<T> ThreadSafeRefCounter<T> {
    pub fn new(data: T) -> Self {
        Self {
            data: Arc::new(std::sync::RwLock::new(data)),
            ref_count: Arc::new(AtomicUsize::new(1)),
        }
    }

    pub fn clone_ref(&self) -> Self {
        self.ref_count.fetch_add(1, Ordering::SeqCst);
        Self { data: Arc::clone(&self.data), ref_count: Arc::clone(&self.ref_count) }
    }

    pub fn read(&self) -> Result<std::sync::RwLockReadGuard<'_, T>, BitNetCError> {
        self.data.read().map_err(|_| BitNetCError("Failed to acquire read lock".to_string()))
    }

    pub fn ref_count(&self) -> usize {
        self.ref_count.load(Ordering::SeqCst)
    }
}

impl<T> Drop for ThreadSafeRefCounter<T> {
    fn drop(&mut self) {
        self.ref_count.fetch_sub(1, Ordering::SeqCst);
    }
}

// Mock thread-local storage
thread_local! {
    static STORAGE: std::cell::RefCell<HashMap<String, String>> = std::cell::RefCell::new(HashMap::new());
}

pub fn set_thread_local(key: &str, value: String) {
    STORAGE.with(|storage| {
        storage.borrow_mut().insert(key.to_string(), value);
    });
}

pub fn get_thread_local(key: &str) -> Option<String> {
    STORAGE.with(|storage| storage.borrow().get(key).cloned())
}

fn get_thread_manager() -> ThreadManager {
    ThreadManager::new()
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("üßµ BitNet.rs FFI Threading Utilities Demo");
    println!("Demonstrating enhancements from PR #179\n");

    // Demonstrate thread pool configuration
    demo_thread_pool_config()?;

    // Demonstrate bounded channel architecture
    demo_bounded_channel_safety()?;

    // Demonstrate RAII job tracking
    demo_raii_job_tracking()?;

    // Demonstrate thread-safe reference counting
    demo_thread_safe_ref_counter()?;

    // Demonstrate thread-local storage
    demo_thread_local_storage()?;

    // Demonstrate error handling
    demo_error_handling()?;

    // Demonstrate graceful shutdown
    demo_graceful_shutdown()?;

    println!("‚úÖ All threading utilities demonstrated successfully!");
    Ok(())
}

/// Demonstrate configurable thread pool setup
fn demo_thread_pool_config() -> Result<(), Box<dyn std::error::Error>> {
    println!("üìã 1. Thread Pool Configuration");

    let config = ThreadPoolConfig {
        num_threads: 4,
        max_queue_size: 100,               // Bounded queue prevents exhaustion
        stack_size: Some(2 * 1024 * 1024), // 2MB stack
        thread_name_prefix: "demo-worker".to_string(),
    };

    println!("   ‚Ä¢ Workers: {}", config.num_threads);
    println!("   ‚Ä¢ Queue limit: {} (prevents memory exhaustion)", config.max_queue_size);
    println!("   ‚Ä¢ Stack size: {} bytes", config.stack_size.unwrap());
    println!("   ‚Ä¢ Name prefix: {}", config.thread_name_prefix);

    // Initialize thread manager with custom config
    let mut manager = ThreadManager::new();
    manager.set_num_threads(config.num_threads)?;
    manager.initialize()?;

    println!("   ‚úÖ Thread pool initialized successfully\n");
    Ok(())
}

/// Demonstrate bounded channel safety preventing resource exhaustion
fn demo_bounded_channel_safety() -> Result<(), Box<dyn std::error::Error>> {
    println!("üõ°Ô∏è  2. Bounded Channel Architecture");

    let manager = get_thread_manager();
    let stats = manager.get_stats()?;

    println!("   ‚Ä¢ Active threads: {}", stats.num_threads);
    println!("   ‚Ä¢ Max queue size: {} (bounded)", stats.max_queue_size);
    println!("   ‚Ä¢ Active jobs: {}", stats.active_jobs);

    // Submit multiple jobs to demonstrate bounded behavior
    let job_count = Arc::new(AtomicUsize::new(0));

    for i in 0..5 {
        let counter = Arc::clone(&job_count);
        manager.execute(move || {
            thread::sleep(Duration::from_millis(100));
            counter.fetch_add(1, Ordering::SeqCst);
            println!("   ‚Üí Job {} completed", i + 1);
        })?;
    }

    // Wait for completion
    manager.wait_for_completion()?;

    let final_count = job_count.load(Ordering::SeqCst);
    println!("   ‚úÖ All {} jobs completed safely\n", final_count);
    Ok(())
}

/// Demonstrate RAII job tracking preventing desynchronization
fn demo_raii_job_tracking() -> Result<(), Box<dyn std::error::Error>> {
    println!("üîÑ 3. RAII Job Tracking");

    let manager = get_thread_manager();

    println!("   ‚Ä¢ Jobs are tracked automatically using RAII patterns");
    println!("   ‚Ä¢ Counter incremented before job submission");
    println!("   ‚Ä¢ Counter decremented after completion OR on error");

    // Demonstrate error handling with proper cleanup
    let result = manager.execute(|| {
        println!("   ‚Üí Job executing with automatic tracking");
        thread::sleep(Duration::from_millis(50));
    });

    match result {
        Ok(()) => println!("   ‚úÖ Job submitted successfully"),
        Err(e) => println!("   ‚ùå Job submission failed: {} (counter still correct)", e),
    }

    // Wait for completion to see final state
    manager.wait_for_completion()?;
    let stats = manager.get_stats()?;
    println!("   ‚Ä¢ Final active jobs: {} (should be 0)\n", stats.active_jobs);
    Ok(())
}

/// Demonstrate thread-safe reference counting
fn demo_thread_safe_ref_counter() -> Result<(), Box<dyn std::error::Error>> {
    println!("üìä 4. Thread-Safe Reference Counting");

    // Create a thread-safe reference counter
    let data = ThreadSafeRefCounter::new("Shared Data".to_string());
    println!("   ‚Ä¢ Initial ref count: {}", data.ref_count());

    // Clone references across threads
    let handles: Vec<_> = (0..3)
        .map(|i| {
            let data_clone = data.clone_ref();
            thread::spawn(move || {
                // Read data safely
                if let Ok(guard) = data_clone.read() {
                    println!(
                        "   ‚Üí Thread {} read: '{}', refs: {}",
                        i + 1,
                        *guard,
                        data_clone.ref_count()
                    );
                }
                thread::sleep(Duration::from_millis(50));

                // Reference automatically decremented when dropped
            })
        })
        .collect();

    // Wait for all threads
    for handle in handles {
        handle.join().unwrap();
    }

    println!("   ‚Ä¢ Final ref count: {} (back to 1)", data.ref_count());
    println!("   ‚úÖ Reference counting managed automatically\n");
    Ok(())
}

/// Demonstrate thread-local storage management
fn demo_thread_local_storage() -> Result<(), Box<dyn std::error::Error>> {
    println!("üóÑÔ∏è  5. Thread-Local Storage");

    // Set thread-local value in main thread
    set_thread_local("config", "main-thread-config".to_string());

    let main_value = get_thread_local("config");
    println!("   ‚Ä¢ Main thread value: {:?}", main_value);

    // Each thread has its own storage
    let handles: Vec<_> = (0..2)
        .map(|i| {
            thread::spawn(move || {
                // Each thread starts with empty storage
                let initial = get_thread_local("config");
                println!("   ‚Üí Thread {} initial: {:?}", i + 1, initial);

                // Set thread-specific value
                set_thread_local("config", format!("thread-{}-config", i + 1));
                let after_set = get_thread_local("config");
                println!("   ‚Üí Thread {} after set: {:?}", i + 1, after_set);
            })
        })
        .collect();

    for handle in handles {
        handle.join().unwrap();
    }

    // Main thread value unchanged
    let final_value = get_thread_local("config");
    println!("   ‚Ä¢ Main thread final: {:?}", final_value);
    println!("   ‚úÖ Thread-local storage isolated correctly\n");
    Ok(())
}

/// Demonstrate enhanced error handling
fn demo_error_handling() -> Result<(), Box<dyn std::error::Error>> {
    println!("‚ö†Ô∏è  6. Enhanced Error Handling");

    // Demonstrate thread safety error
    println!("   ‚Ä¢ Thread safety errors are properly categorized");
    let error = BitNetCError("Demo thread safety violation".to_string());
    println!("   ‚Üí Error: {}", error);

    // Demonstrate invalid argument error
    println!("   ‚Ä¢ Invalid arguments are validated with clear messages");
    let error = BitNetCError("Demo invalid argument".to_string());
    println!("   ‚Üí Error: {}", error);

    // Demonstrate inference error
    println!("   ‚Ä¢ Inference errors provide context");
    let error = BitNetCError("Demo inference failure".to_string());
    println!("   ‚Üí Error: {}", error);

    println!("   ‚úÖ Error handling provides clear, actionable messages\n");
    Ok(())
}

/// Demonstrate graceful shutdown and cleanup
fn demo_graceful_shutdown() -> Result<(), Box<dyn std::error::Error>> {
    println!("üõë 7. Graceful Shutdown");

    let manager = get_thread_manager();

    // Submit some long-running jobs
    println!("   ‚Ä¢ Submitting jobs before shutdown...");
    for i in 0..3 {
        manager.execute(move || {
            println!("   ‚Üí Long job {} starting", i + 1);
            thread::sleep(Duration::from_millis(200));
            println!("   ‚Üí Long job {} finished", i + 1);
        })?;
    }

    println!("   ‚Ä¢ Initiating graceful shutdown...");

    // Wait for completion before cleanup
    manager.wait_for_completion()?;

    // Cleanup resources
    manager.cleanup()?;

    let stats = manager.get_stats();
    match stats {
        Ok(s) => println!("   ‚Ä¢ Jobs after cleanup: {}", s.active_jobs),
        Err(_) => println!("   ‚Ä¢ Thread pool cleaned up (no longer available)"),
    }

    println!("   ‚úÖ Shutdown completed gracefully\n");
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_demo_functions() {
        // Test that all demo functions can run without panicking
        assert!(demo_thread_pool_config().is_ok());
        assert!(demo_bounded_channel_safety().is_ok());
        assert!(demo_raii_job_tracking().is_ok());
        assert!(demo_thread_safe_ref_counter().is_ok());
        assert!(demo_thread_local_storage().is_ok());
        assert!(demo_error_handling().is_ok());
        assert!(demo_graceful_shutdown().is_ok());
    }

    #[test]
    fn test_thread_pool_configuration() {
        let config = ThreadPoolConfig {
            num_threads: 2,
            max_queue_size: 50,
            stack_size: Some(1024 * 1024),
            thread_name_prefix: "test-worker".to_string(),
        };

        assert_eq!(config.num_threads, 2);
        assert_eq!(config.max_queue_size, 50);
        assert_eq!(config.stack_size, Some(1024 * 1024));
        assert_eq!(config.thread_name_prefix, "test-worker");
    }

    #[test]
    fn test_thread_safe_ref_counter() {
        let counter = ThreadSafeRefCounter::new(42);
        assert_eq!(counter.ref_count(), 1);

        let cloned = counter.clone_ref();
        assert_eq!(counter.ref_count(), 2);
        assert_eq!(cloned.ref_count(), 2);

        // Test reading
        {
            let data = counter.read().unwrap();
            assert_eq!(*data, 42);
        }

        drop(cloned);
        assert_eq!(counter.ref_count(), 1);
    }
}
