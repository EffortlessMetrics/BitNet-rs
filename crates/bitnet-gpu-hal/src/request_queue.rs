//! Request queue management for batched inference.
