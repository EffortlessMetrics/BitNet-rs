BitNet CLI - High-performance 1-bit LLM inference

Usage: bitnet-cli [OPTIONS] <COMMAND>

Commands:
  infer      Run inference on a model
  convert    Convert model between formats
  benchmark  Run performance benchmarks
  server     Start inference server
  help       Print this message or the help of the given subcommand(s)

Options:
  -v, --verbose  Enable verbose output
  -h, --help     Print help
  -V, --version  Print version

Examples:
  bitnet-cli infer --model model.gguf --prompt "Hello world"
  bitnet-cli convert --input model.safetensors --output model.gguf
  bitnet-cli benchmark --model model.gguf --iterations 100
  bitnet-cli server --model model.gguf --port 8080