name: Release Gates - Dual Format Validation

on:
  pull_request:
    paths:
      - 'crates/**/*.rs'
      - 'models/**/*.gguf'
      - 'models/**/*.safetensors'
      - 'docs/PERF_*.md'
      - 'scripts/*.sh'
  schedule:
    - cron: '0 2 * * *'  # Nightly at 2 AM UTC

env:
  RUST_BACKTRACE: 1
  BITNET_DETERMINISTIC: 1
  BITNET_SEED: 42
  RAYON_NUM_THREADS: 1

jobs:
  pr-gates:
    name: PR Release Gates
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Check for mock features
        run: |
          # Fail if any Cargo.toml includes mock features
          if grep -r "features.*mocks" crates/*/Cargo.toml; then
            echo "âŒ ERROR: Mock features detected in PR"
            echo "Remove all mock features before merging"
            exit 1
          fi
      
      - name: Check GGUF changes require validation
        run: |
          # Check if GGUF files changed
          if git diff --name-only origin/main...HEAD | grep -q '\.gguf$'; then
            echo "GGUF files changed - validation required"
            echo "GGUF_CHANGED=true" >> $GITHUB_ENV
          fi
      
      - name: Check performance docs have measurements
        run: |
          # Check if perf docs changed
          if git diff --name-only origin/main...HEAD | grep -q 'docs/PERF_.*\.md$'; then
            # Verify corresponding JSON exists
            for doc in $(git diff --name-only origin/main...HEAD | grep 'docs/PERF_.*\.md$'); do
              platform=$(echo $doc | sed 's/docs\/PERF_\(.*\)_.*\.md/\1/')
              if ! git diff --name-only origin/main...HEAD | grep -q "bench/results/${platform}.*\.json"; then
                echo "âŒ ERROR: Performance doc $doc changed without measurement JSON"
                echo "Add bench/results/${platform}-*.json with actual measurements"
                exit 1
              fi
            done
          fi
      
      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: 1.89.0
      
      - name: Run format validation
        if: env.GGUF_CHANGED == 'true'
        run: |
          cargo build --release --no-default-features --features cpu
          ./scripts/validate_format_parity.sh
      
      - name: Verify JSON measurements
        run: |
          # Check all bench JSON files are valid
          for json in bench/results/*.json; do
            if [ -f "$json" ]; then
              jq empty "$json" || {
                echo "âŒ Invalid JSON: $json"
                exit 1
              }
              # Check required fields
              jq -e '.metadata.platform' "$json" > /dev/null || {
                echo "âŒ Missing platform metadata in $json"
                exit 1
              }
              jq -e '.measurements' "$json" > /dev/null || {
                echo "âŒ Missing measurements in $json"
                exit 1
              }
            fi
          done

  nightly-strict:
    name: Nightly Strict Validation
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: 1.89.0
      
      - name: Install Python dependencies
        run: |
          pip install transformers torch safetensors
      
      - name: Build BitNet
        run: |
          cargo build --release --no-default-features --features cpu
      
      - name: Download test model
        run: |
          cargo run -p xtask -- download-model
      
      - name: Run strict validation
        run: |
          # Stricter thresholds for nightly
          export TAU_MIN=0.95  # FP32â†”FP32
          export DELTA_NLL_MAX=1e-2  # FP32â†”FP32
          export PROP_EXAMPLES=100
          export TAU_STEPS=32
          
          # Run comprehensive validation
          ./scripts/reality_proof_checklist.sh | tee validation.log
          
          # Save exit code
          echo "VALIDATION_EXIT_CODE=$?" >> $GITHUB_ENV
      
      - name: Upload validation artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: nightly-validation-${{ github.run_id }}
          path: |
            reality_proof_results/
            validation.log
            bench/results/*.json
            artifacts/parity_failures.jsonl
      
      - name: Create issue on failure
        if: env.VALIDATION_EXIT_CODE != '0'
        uses: actions/github-script@v6
        with:
          script: |
            const issue = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ðŸš¨ Nightly validation failed - ${new Date().toISOString().split('T')[0]}`,
              body: `## Nightly Validation Failed
              
              The strict nightly validation has detected issues with dual-format support.
              
              **Run ID:** ${{ github.run_id }}
              **Artifacts:** [Download validation results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
              
              ### Required Actions
              - [ ] Review validation.log for specific failures
              - [ ] Check parity_failures.jsonl for divergent examples
              - [ ] Verify Ï„-b correlation meets thresholds (â‰¥0.95 for FP32)
              - [ ] Ensure |Î” NLL| â‰¤ 1e-2 for FP32â†”FP32
              
              ### Debugging Steps
              1. Download artifacts from the run
              2. Run \`scripts/replay_parity.py\` on failures
              3. Check platform-specific issues in reality_proof_results/
              
              cc @maintainers`,
              labels: ['bug', 'validation', 'high-priority']
            });
            console.log(`Created issue #${issue.data.number}`);

  format-comparison:
    name: SafeTensors vs GGUF Performance
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: 1.89.0
      
      - name: Build and measure
        run: |
          cargo build --release --no-default-features --features cpu
          
          # Download models if needed
          if [ ! -d "models" ]; then
            cargo run -p xtask -- download-model
          fi
          
          # Measure both formats
          ./scripts/measure_perf_json.sh
      
      - name: Compare performance
        run: |
          # Extract and compare key metrics
          platform=$(uname -s)-$(uname -m)
          st_json="bench/results/${platform}-safetensors.json"
          gguf_json="bench/results/${platform}-gguf.json"
          
          if [ -f "$st_json" ] && [ -f "$gguf_json" ]; then
            st_tps=$(jq '.measurements.tokens_per_second.median' "$st_json")
            gguf_tps=$(jq '.measurements.tokens_per_second.median' "$gguf_json")
            
            echo "## Performance Comparison"
            echo "- SafeTensors: ${st_tps} tokens/sec"
            echo "- GGUF: ${gguf_tps} tokens/sec"
            
            # Calculate ratio
            ratio=$(echo "scale=2; $gguf_tps / $st_tps" | bc)
            echo "- Ratio (GGUF/ST): ${ratio}x"
          fi
      
      - name: Post PR comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const platform = process.platform + '-' + process.arch;
            
            try {
              const stJson = JSON.parse(fs.readFileSync(`bench/results/${platform}-safetensors.json`));
              const ggufJson = JSON.parse(fs.readFileSync(`bench/results/${platform}-gguf.json`));
              
              const comment = `## ðŸ“Š Format Performance Comparison
              
              | Metric | SafeTensors | GGUF | Ratio |
              |--------|------------|------|-------|
              | Tokens/sec | ${stJson.measurements.tokens_per_second.median.toFixed(2)} | ${ggufJson.measurements.tokens_per_second.median.toFixed(2)} | ${(ggufJson.measurements.tokens_per_second.median / stJson.measurements.tokens_per_second.median).toFixed(2)}x |
              | First Token (ms) | ${stJson.measurements.time_to_first_token.median.toFixed(2)} | ${ggufJson.measurements.time_to_first_token.median.toFixed(2)} | ${(ggufJson.measurements.time_to_first_token.median / stJson.measurements.time_to_first_token.median).toFixed(2)}x |
              | Memory (MB) | ${stJson.measurements.memory_mb.peak} | ${ggufJson.measurements.memory_mb.peak} | ${(ggufJson.measurements.memory_mb.peak / stJson.measurements.memory_mb.peak).toFixed(2)}x |
              
              <details>
              <summary>Platform Details</summary>
              
              \`\`\`
              Platform: ${stJson.metadata.platform}
              BitNet: ${stJson.metadata.bitnet_version}
              Deterministic: ${stJson.metadata.deterministic}
              \`\`\`
              </details>`;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            } catch (e) {
              console.log('Could not post performance comparison:', e);
            }