name: Validate Artifacts

on:
  pull_request:
    paths:
      - 'bench/results/*.json'
      - 'bench/schema/*.json'
      - 'artifacts/*.json'
  push:
    branches: [main]
    paths:
      - 'bench/results/*.json'
      - 'bench/schema/*.json'

jobs:
  validate-json-schemas:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install jsonschema
        run: pip install jsonschema
      
      - name: Validate Performance JSONs
        run: |
          python3 - <<'EOF'
          import json
          import sys
          import glob
          from jsonschema import validate, Draft7Validator, ValidationError
          
          # Load performance schema
          with open('bench/schema/perf.schema.json') as f:
              perf_schema = json.load(f)
          
          # Validate all performance JSONs
          errors = []
          for json_file in glob.glob('bench/results/*-*.json'):
              try:
                  with open(json_file) as f:
                      data = json.load(f)
                  Draft7Validator(perf_schema).validate(data)
                  print(f"✅ Valid: {json_file}")
              except ValidationError as e:
                  errors.append(f"❌ {json_file}: {e.message}")
              except Exception as e:
                  errors.append(f"❌ {json_file}: {str(e)}")
          
          if errors:
              print("\n".join(errors))
              sys.exit(1)
          EOF
      
      - name: Validate Parity JSONs
        if: always()
        run: |
          python3 - <<'EOF'
          import json
          import sys
          import glob
          import os
          from jsonschema import validate, Draft7Validator, ValidationError
          
          # Load parity schema
          with open('bench/schema/parity.schema.json') as f:
              parity_schema = json.load(f)
          
          # Validate all parity JSONs
          errors = []
          for json_file in glob.glob('artifacts/*parity*.json'):
              if not os.path.exists(json_file):
                  continue
              try:
                  with open(json_file) as f:
                      data = json.load(f)
                  Draft7Validator(parity_schema).validate(data)
                  print(f"✅ Valid: {json_file}")
              except ValidationError as e:
                  errors.append(f"❌ {json_file}: {e.message}")
              except Exception as e:
                  errors.append(f"❌ {json_file}: {str(e)}")
          
          if errors:
              print("\n".join(errors))
              sys.exit(1)
          EOF
      
      - name: Check Provenance Fields
        run: |
          python3 - <<'EOF'
          import json
          import sys
          import glob
          
          required_provenance = ['git_commit', 'git_dirty', 'model_hash', 'schema_version']
          
          for json_file in glob.glob('bench/results/*.json'):
              with open(json_file) as f:
                  data = json.load(f)
              
              missing = [field for field in required_provenance if field not in data]
              if missing:
                  print(f"❌ {json_file} missing provenance fields: {missing}")
                  sys.exit(1)
              
              # Validate schema version
              if data.get('schema_version') != 1:
                  print(f"❌ {json_file} has incorrect schema version: {data.get('schema_version')}")
                  sys.exit(1)
              
              print(f"✅ {json_file} has complete provenance")
          EOF
      
      - name: Validate Perf MD Generation
        run: |
          # Check that PERF_COMPARISON.md matches JSON sources
          if [ -f docs/PERF_COMPARISON.md ]; then
            # Find latest safetensors and gguf JSONs
            LATEST_ST=$(ls -t bench/results/*-safetensors.json 2>/dev/null | head -1)
            LATEST_GGUF=$(ls -t bench/results/*-gguf.json 2>/dev/null | head -1)
            
            if [ -n "$LATEST_ST" ] && [ -n "$LATEST_GGUF" ]; then
              # Regenerate and compare
              python3 scripts/render_perf_md.py "$LATEST_ST" "$LATEST_GGUF" > /tmp/perf_check.md
              
              # Check if different (ignoring timestamps)
              if ! diff -q <(grep -v "Generated from" docs/PERF_COMPARISON.md) \
                           <(grep -v "Generated from" /tmp/perf_check.md) >/dev/null; then
                echo "❌ PERF_COMPARISON.md is out of sync with JSON sources"
                echo "Run: python3 scripts/render_perf_md.py $LATEST_ST $LATEST_GGUF > docs/PERF_COMPARISON.md"
                exit 1
              fi
              echo "✅ PERF_COMPARISON.md is in sync with JSON sources"
            fi
          fi