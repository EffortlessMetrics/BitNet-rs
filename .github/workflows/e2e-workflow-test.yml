name: End-to-End Workflow Testing

on:
  schedule:
    # Run E2E tests weekly
    - cron: "0 10 * * 0" # Sunday 10 AM UTC
  workflow_dispatch:
    inputs:
      test_scope:
        description: "Test scope"
        required: false
        default: "full"
        type: choice
        options:
          - full
          - development
          - deployment
          - distribution
  push:
    branches: [main]
    paths:
      - ".github/workflows/**"

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  # Test complete development workflow
  development-workflow:
    name: Development Workflow Test
    runs-on: ubuntu-latest
    if: |
      github.event.inputs.test_scope == 'full' ||
      github.event.inputs.test_scope == 'development' ||
      github.event.inputs.test_scope == ''

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Test developer setup workflow
        run: |
          echo "Testing developer setup workflow..."

          # Test xtask functionality
          echo "1. Testing xtask commands..."
          cargo xtask --help

          # Test fixture generation
          echo "2. Testing fixture generation..."
          cargo xtask gen-fixtures --size tiny --output /tmp/test-fixtures/

          # Verify fixtures were created
          if [[ -d "/tmp/test-fixtures" ]]; then
            echo "‚úÖ Fixtures generated successfully"
            ls -la /tmp/test-fixtures/
          else
            echo "‚ùå Fixture generation failed"
            exit 1
          fi

          # Test feature checking
          echo "3. Testing feature consistency check..."
          cargo xtask check-features

      - name: Test development build workflow
        run: |
          echo "Testing development build workflow..."

          # Test fast Rust-only build
          echo "1. Testing fast Rust build..."
          time cargo build --workspace

          # Test with different feature combinations
          echo "2. Testing feature combinations..."
          cargo build --workspace --no-default-features
          cargo build --workspace --features cpu
          cargo build --workspace --features cpu,avx2

          # Test individual crate builds
          echo "3. Testing individual crate builds..."
          cargo build --package bitnet-common
          cargo build --package bitnet-cli
          cargo build --package bitnet-server

      - name: Test development test workflow
        run: |
          echo "Testing development test workflow..."

          # Test fast test suite
          echo "1. Running fast test suite..."
          cargo test --workspace --lib

          # Test documentation tests
          echo "2. Running documentation tests..."
          cargo test --workspace --doc

          # Test integration tests
          echo "3. Running integration tests..."
          cargo test --workspace --test '*'

      - name: Test cross-validation setup workflow
        run: |
          echo "Testing cross-validation setup workflow..."

          # Test dev-crossval script
          echo "1. Testing dev-crossval script..."
          chmod +x scripts/dev-crossval.sh
          ./scripts/dev-crossval.sh --fixtures-only

          # Test cache setup
          echo "2. Testing cache setup..."
          chmod +x ci/use-bitnet-cpp-cache.sh
          ./ci/use-bitnet-cpp-cache.sh || echo "Cache setup failed (expected in CI)"

  # Test CI/CD pipeline validation
  cicd-pipeline-test:
    name: CI/CD Pipeline Test
    runs-on: ubuntu-latest
    if: |
      github.event.inputs.test_scope == 'full' ||
      github.event.inputs.test_scope == 'development' ||
      github.event.inputs.test_scope == ''

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Validate workflow files
        run: |
          echo "Validating GitHub Actions workflow files..."

          # Check workflow syntax
          for workflow in .github/workflows/*.yml; do
            echo "Checking $workflow..."
            # Basic YAML syntax check
            python3 -c "import yaml; yaml.safe_load(open('$workflow'))" || echo "‚ùå $workflow has YAML syntax errors"
          done

          echo "‚úÖ Workflow files validated"

      - name: Test workflow triggers
        run: |
          echo "Testing workflow trigger conditions..."

          # Check that main workflows have appropriate triggers
          main_workflows=(
            "ci.yml"
            "release-binaries.yml"
            "publish-crates.yml"
            "comprehensive-build-test.yml"
          )

          for workflow in "${main_workflows[@]}"; do
            if [[ -f ".github/workflows/$workflow" ]]; then
              echo "‚úÖ $workflow exists"

              # Check for push/PR triggers
              if grep -q "on:" ".github/workflows/$workflow"; then
                echo "  ‚úÖ Has trigger configuration"
              else
                echo "  ‚ùå Missing trigger configuration"
              fi
            else
              echo "‚ùå $workflow missing"
            fi
          done

      - name: Test environment consistency
        run: |
          echo "Testing environment consistency across workflows..."

          # Check that environment variables are consistent
          echo "Checking CARGO_TERM_COLOR usage..."
          grep -r "CARGO_TERM_COLOR" .github/workflows/ || echo "No CARGO_TERM_COLOR found"

          echo "Checking Rust toolchain consistency..."
          grep -r "dtolnay/rust-toolchain" .github/workflows/ || echo "No Rust toolchain setup found"

  # Test deployment workflow
  deployment-workflow:
    name: Deployment Workflow Test
    runs-on: ubuntu-latest
    if: |
      github.event.inputs.test_scope == 'full' ||
      github.event.inputs.test_scope == 'deployment' ||
      github.event.inputs.test_scope == ''

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Test Docker configuration
        run: |
          echo "Testing Docker configuration..."

          # Check Dockerfile exists and is valid
          if [[ -f "Dockerfile" ]]; then
            echo "‚úÖ Main Dockerfile exists"
            docker build --dry-run -f Dockerfile . || echo "‚ùå Dockerfile has issues"
          fi

          # Check Docker Compose configuration
          if [[ -f "docker-compose.yml" ]]; then
            echo "‚úÖ Docker Compose file exists"
            # docker-compose config || echo "‚ùå Docker Compose has issues"
          fi

          # Check monitoring Docker setup
          if [[ -f "monitoring/docker-compose.yml" ]]; then
            echo "‚úÖ Monitoring Docker Compose exists"
          fi

      - name: Test Kubernetes configuration
        run: |
          echo "Testing Kubernetes configuration..."

          # Check K8s manifests
          if [[ -d "k8s" ]]; then
            echo "‚úÖ Kubernetes manifests directory exists"

            for manifest in k8s/*.yaml; do
              if [[ -f "$manifest" ]]; then
                echo "Checking $manifest..."
                # Basic YAML validation
                python3 -c "import yaml; yaml.safe_load(open('$manifest'))" || echo "‚ùå $manifest has YAML errors"
              fi
            done
          fi

          # Check Helm charts
          if [[ -d "helm/bitnet" ]]; then
            echo "‚úÖ Helm chart exists"

            # Validate Helm chart
            if command -v helm >/dev/null 2>&1; then
              helm lint helm/bitnet || echo "‚ùå Helm chart has issues"
            else
              echo "Helm not available for validation"
            fi
          fi

      - name: Test monitoring configuration
        run: |
          echo "Testing monitoring configuration..."

          # Check Prometheus configuration
          if [[ -f "monitoring/prometheus.yml" ]]; then
            echo "‚úÖ Prometheus config exists"
            # Basic YAML validation
            python3 -c "import yaml; yaml.safe_load(open('monitoring/prometheus.yml'))" || echo "‚ùå Prometheus config has errors"
          fi

          # Check Grafana dashboards
          if [[ -d "monitoring/grafana/dashboards" ]]; then
            echo "‚úÖ Grafana dashboards exist"

            for dashboard in monitoring/grafana/dashboards/*.json; do
              if [[ -f "$dashboard" ]]; then
                echo "Checking $dashboard..."
                python3 -c "import json; json.load(open('$dashboard'))" || echo "‚ùå $dashboard has JSON errors"
              fi
            done
          fi

  # Test distribution workflow
  distribution-workflow:
    name: Distribution Workflow Test
    runs-on: ubuntu-latest
    if: |
      github.event.inputs.test_scope == 'full' ||
      github.event.inputs.test_scope == 'distribution' ||
      github.event.inputs.test_scope == ''

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Test package configuration
        run: |
          echo "Testing package configuration..."

          # Test version consistency
          echo "1. Testing version consistency..."
          chmod +x scripts/verify-versions.sh
          ./scripts/verify-versions.sh

      - name: Test installation scripts
        run: |
          echo "Testing installation scripts..."

          # Test Unix installation script syntax
          if [[ -f "scripts/install.sh" ]]; then
            echo "‚úÖ Unix installation script exists"
            bash -n scripts/install.sh || echo "‚ùå Unix script has syntax errors"

            # Test help functionality
            bash scripts/install.sh --help || echo "‚ùå Unix script help failed"
          fi

          # Test PowerShell script (basic syntax check)
          if [[ -f "scripts/install.ps1" ]]; then
            echo "‚úÖ PowerShell installation script exists"
            # PowerShell syntax validation would require PowerShell
          fi

      - name: Test package manager configurations
        run: |
          echo "Testing package manager configurations..."

          # Test Homebrew formula
          if [[ -f "packaging/homebrew/bitnet-rs.rb" ]]; then
            echo "‚úÖ Homebrew formula exists"
            ruby -c packaging/homebrew/bitnet-rs.rb || echo "‚ùå Homebrew formula has syntax errors"
          fi

          # Test Chocolatey package
          if [[ -f "packaging/chocolatey/bitnet-rs.nuspec" ]]; then
            echo "‚úÖ Chocolatey package spec exists"
            # XML validation
            python3 -c "
          import xml.etree.ElementTree as ET
          try:
              ET.parse('packaging/chocolatey/bitnet-rs.nuspec')
              print('  ‚úÖ Chocolatey spec is valid XML')
          except ET.ParseError as e:
              print(f'  ‚ùå Chocolatey spec has XML errors: {e}')
          "
          fi

          # Test Snap package
          if [[ -f "packaging/snap/snapcraft.yaml" ]]; then
            echo "‚úÖ Snap package config exists"
            python3 -c "import yaml; yaml.safe_load(open('packaging/snap/snapcraft.yaml'))" || echo "‚ùå Snap config has YAML errors"
          fi

      - name: Test binary build process
        run: |
          echo "Testing binary build process..."

          # Test CLI binary build
          echo "1. Building CLI binary..."
          cargo build --package bitnet-cli --release

          # Test server binary build
          echo "2. Building server binary..."
          cargo build --package bitnet-server --release

          # Test binary functionality
          echo "3. Testing binary functionality..."
          ./target/release/bitnet-cli --version
          ./target/release/bitnet-cli --help

          ./target/release/bitnet-server --version
          ./target/release/bitnet-server --help

  # Generate comprehensive E2E report
  e2e-summary:
    name: E2E Test Summary
    needs:
      [
        development-workflow,
        cicd-pipeline-test,
        deployment-workflow,
        distribution-workflow,
      ]
    if: always()
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Generate E2E test report
        run: |
          cat > e2e-test-report.md << 'EOF'
          # üîÑ End-to-End Workflow Test Report

          **Date**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Trigger**: ${{ github.event_name }}
          **Scope**: ${{ github.event.inputs.test_scope || 'full' }}

          ## Test Results Summary

          ### Development Workflow
          EOF

          if [[ "${{ needs.development-workflow.result }}" == "success" ]]; then
            echo "- ‚úÖ **Developer Setup**: All tools working correctly" >> e2e-test-report.md
            echo "- ‚úÖ **Build Workflow**: Fast Rust builds confirmed" >> e2e-test-report.md
            echo "- ‚úÖ **Test Workflow**: Comprehensive test suite passing" >> e2e-test-report.md
            echo "- ‚úÖ **Cross-validation Setup**: Environment ready" >> e2e-test-report.md
          else
            echo "- ‚ùå **Development Workflow**: Issues detected" >> e2e-test-report.md
          fi

          echo "" >> e2e-test-report.md
          echo "### CI/CD Pipeline" >> e2e-test-report.md

          if [[ "${{ needs.cicd-pipeline-test.result }}" == "success" ]]; then
            echo "- ‚úÖ **Workflow Files**: All workflows valid" >> e2e-test-report.md
            echo "- ‚úÖ **Trigger Configuration**: Properly configured" >> e2e-test-report.md
            echo "- ‚úÖ **Environment Consistency**: Maintained across workflows" >> e2e-test-report.md
          else
            echo "- ‚ùå **CI/CD Pipeline**: Issues detected" >> e2e-test-report.md
          fi

          echo "" >> e2e-test-report.md
          echo "### Deployment Workflow" >> e2e-test-report.md

          if [[ "${{ needs.deployment-workflow.result }}" == "success" ]]; then
            echo "- ‚úÖ **Docker Configuration**: Containers ready" >> e2e-test-report.md
            echo "- ‚úÖ **Kubernetes Setup**: Manifests and Helm charts valid" >> e2e-test-report.md
            echo "- ‚úÖ **Monitoring Stack**: Prometheus and Grafana configured" >> e2e-test-report.md
          else
            echo "- ‚ùå **Deployment Workflow**: Issues detected" >> e2e-test-report.md
          fi

          echo "" >> e2e-test-report.md
          echo "### Distribution Workflow" >> e2e-test-report.md

          if [[ "${{ needs.distribution-workflow.result }}" == "success" ]]; then
            echo "- ‚úÖ **Package Configuration**: All package managers ready" >> e2e-test-report.md
            echo "- ‚úÖ **Installation Scripts**: Working correctly" >> e2e-test-report.md
            echo "- ‚úÖ **Binary Builds**: CLI and server binaries functional" >> e2e-test-report.md
          else
            echo "- ‚ùå **Distribution Workflow**: Issues detected" >> e2e-test-report.md
          fi

          echo "" >> e2e-test-report.md
          echo "## Overall Assessment" >> e2e-test-report.md
          echo "" >> e2e-test-report.md

          # Count successful workflows
          success_count=0
          total_count=4

          [[ "${{ needs.development-workflow.result }}" == "success" ]] && success_count=$((success_count + 1))
          [[ "${{ needs.cicd-pipeline-test.result }}" == "success" ]] && success_count=$((success_count + 1))
          [[ "${{ needs.deployment-workflow.result }}" == "success" ]] && success_count=$((success_count + 1))
          [[ "${{ needs.distribution-workflow.result }}" == "success" ]] && success_count=$((success_count + 1))

          echo "**Success Rate**: $success_count/$total_count workflows passed" >> e2e-test-report.md
          echo "" >> e2e-test-report.md

          if [[ $success_count -eq $total_count ]]; then
            echo "üéâ **Status**: ALL E2E TESTS PASSED" >> e2e-test-report.md
            echo "" >> e2e-test-report.md
            echo "The BitNet.rs repository is ready for:" >> e2e-test-report.md
            echo "- ‚úÖ Development workflows" >> e2e-test-report.md
            echo "- ‚úÖ CI/CD automation" >> e2e-test-report.md
            echo "- ‚úÖ Production deployment" >> e2e-test-report.md
            echo "- ‚úÖ Package distribution" >> e2e-test-report.md
          else
            echo "‚ö†Ô∏è **Status**: SOME E2E TESTS FAILED" >> e2e-test-report.md
            echo "" >> e2e-test-report.md
            echo "Review failed workflows and address issues before proceeding." >> e2e-test-report.md
          fi

          echo "" >> e2e-test-report.md
          echo "---" >> e2e-test-report.md
          echo "*Report generated by End-to-End Workflow Testing*" >> e2e-test-report.md

      - name: Upload E2E test report
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-report
          path: e2e-test-report.md
          retention-days: 90

      - name: Check overall E2E success
        run: |
          success_count=0
          total_count=4

          [[ "${{ needs.development-workflow.result }}" == "success" ]] && success_count=$((success_count + 1))
          [[ "${{ needs.cicd-pipeline-test.result }}" == "success" ]] && success_count=$((success_count + 1))
          [[ "${{ needs.deployment-workflow.result }}" == "success" ]] && success_count=$((success_count + 1))
          [[ "${{ needs.distribution-workflow.result }}" == "success" ]] && success_count=$((success_count + 1))

          echo "E2E Test Results: $success_count/$total_count workflows passed"

          if [[ $success_count -eq $total_count ]]; then
            echo "üéâ All E2E tests passed! Repository is ready for production."
          else
            echo "‚ö†Ô∏è Some E2E tests failed. Review and fix issues."
            exit 1
          fi
