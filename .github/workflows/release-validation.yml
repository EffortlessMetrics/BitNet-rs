name: Release Validation Pipeline

on:
  workflow_dispatch:
    inputs:
      release_candidate:
        description: "Release candidate version (e.g., v1.0.0-rc.1)"
        required: true
        type: string
      baseline_version:
        description: "Baseline version for performance comparison (e.g., v0.9.0)"
        required: false
        type: string
        default: "main"
      skip_performance:
        description: "Skip performance validation"
        required: false
        type: boolean
        default: false
      skip_crossval:
        description: "Skip cross-validation tests"
        required: false
        type: boolean
        default: false

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1
  BITNET_TEST_CACHE: ${{ github.workspace }}/test-cache

jobs:
  # Pre-validation checks
  pre_validation:
    name: Pre-validation Checks
    runs-on: ubuntu-latest
    outputs:
      should_run_performance: ${{ steps.checks.outputs.should_run_performance }}
      should_run_crossval: ${{ steps.checks.outputs.should_run_crossval }}
      baseline_ref: ${{ steps.checks.outputs.baseline_ref }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Validate release candidate version
        id: validate_version
        run: |
          RC_VERSION="${{ github.event.inputs.release_candidate }}"
          if [[ ! "$RC_VERSION" =~ ^v[0-9]+\.[0-9]+\.[0-9]+(-rc\.[0-9]+)?$ ]]; then
            echo "Invalid release candidate version format: $RC_VERSION"
            echo "Expected format: v1.0.0 or v1.0.0-rc.1"
            exit 1
          fi
          echo "version=$RC_VERSION" >> $GITHUB_OUTPUT

      - name: Check if tag exists
        run: |
          RC_VERSION="${{ steps.validate_version.outputs.version }}"
          if git tag -l | grep -q "^$RC_VERSION$"; then
            echo "Tag $RC_VERSION already exists"
            exit 1
          fi

      - name: Determine validation scope
        id: checks
        run: |
          echo "should_run_performance=${{ !github.event.inputs.skip_performance }}" >> $GITHUB_OUTPUT
          echo "should_run_crossval=${{ !github.event.inputs.skip_crossval }}" >> $GITHUB_OUTPUT
          echo "baseline_ref=${{ github.event.inputs.baseline_version }}" >> $GITHUB_OUTPUT

  # Cross-platform validation matrix
  cross_platform_validation:
    name: Cross-platform Validation
    needs: pre_validation
    strategy:
      fail-fast: false
      matrix:
        include:
          # Linux variants
          - os: ubuntu-latest
            target: x86_64-unknown-linux-gnu
            features: default
            rust: stable
          - os: ubuntu-latest
            target: x86_64-unknown-linux-gnu
            features: gpu
            rust: stable
          - os: ubuntu-20.04
            target: x86_64-unknown-linux-gnu
            features: default
            rust: stable

          # macOS variants
          - os: macos-latest
            target: x86_64-apple-darwin
            features: default
            rust: stable
          - os: macos-latest
            target: aarch64-apple-darwin
            features: default
            rust: stable

          # Windows variants
          - os: windows-latest
            target: x86_64-pc-windows-msvc
            features: default
            rust: stable
          - os: windows-latest
            target: x86_64-pc-windows-gnu
            features: default
            rust: stable

          # Rust version compatibility
          - os: ubuntu-latest
            target: x86_64-unknown-linux-gnu
            features: default
            rust: 1.70.0 # MSRV
          - os: ubuntu-latest
            target: x86_64-unknown-linux-gnu
            features: default
            rust: beta
          - os: ubuntu-latest
            target: x86_64-unknown-linux-gnu
            features: default
            rust: nightly

    runs-on: ${{ matrix.os }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: ${{ matrix.rust }}
          targets: ${{ matrix.target }}

      - name: Setup cache
        uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
            test-cache
          key: ${{ runner.os }}-${{ matrix.target }}-${{ matrix.rust }}-${{ matrix.features }}-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-${{ matrix.target }}-${{ matrix.rust }}-${{ matrix.features }}-
            ${{ runner.os }}-${{ matrix.target }}-${{ matrix.rust }}-
            ${{ runner.os }}-${{ matrix.target }}-

      - name: Install system dependencies (Linux)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential pkg-config

      - name: Install system dependencies (macOS)
        if: runner.os == 'macOS'
        run: |
          brew install pkg-config

      - name: Build with target features
        run: |
          if [ "${{ matrix.features }}" = "gpu" ]; then
            cargo build --release --target ${{ matrix.target }} --features gpu
          else
            cargo build --release --target ${{ matrix.target }}
          fi

      - name: Run unit tests
        run: |
          if [ "${{ matrix.features }}" = "gpu" ]; then
            cargo test --release --target ${{ matrix.target }} --features gpu
          else
            cargo test --release --target ${{ matrix.target }}
          fi

      - name: Run integration tests
        run: |
          if [ "${{ matrix.features }}" = "gpu" ]; then
            cargo test --release --target ${{ matrix.target }} --features gpu --test '*'
          else
            cargo test --release --target ${{ matrix.target }} --test '*'
          fi

      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build-${{ matrix.os }}-${{ matrix.target }}-${{ matrix.features }}
          path: |
            target/${{ matrix.target }}/release/bitnet*
            target/${{ matrix.target }}/release/*.dll
            target/${{ matrix.target }}/release/*.so
            target/${{ matrix.target }}/release/*.dylib
          retention-days: 7

  # Comprehensive test suite validation
  comprehensive_testing:
    name: Comprehensive Test Suite
    needs: pre_validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Setup cache
        uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
            test-cache
          key: comprehensive-${{ hashFiles('**/Cargo.lock') }}

      - name: Install test dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential pkg-config
          cargo install cargo-tarpaulin --locked

      - name: Run comprehensive unit tests
        run: |
          cargo test --release --all-features --workspace -- --test-threads=1
        env:
          RUST_LOG: debug

      - name: Run integration tests
        run: |
          cargo test --release --all-features --test '*' -- --test-threads=1
        env:
          RUST_LOG: debug

      - name: Run cross-validation tests
        if: needs.pre_validation.outputs.should_run_crossval == 'true'
        run: |
          cargo test --release --all-features crossval -- --test-threads=1
        env:
          RUST_LOG: debug

      - name: Generate coverage report
        run: |
          cargo tarpaulin --release --all-features --workspace --timeout 300 \
            --exclude-files 'target/*' --exclude-files 'tests/*' \
            --out Html --out Json --output-dir coverage-report
        env:
          RUST_LOG: info

      - name: Check coverage threshold
        run: |
          python3 scripts/check_coverage.py coverage-report/tarpaulin-report.json 85.0

      - name: Upload coverage report
        uses: actions/upload-artifact@v3
        with:
          name: coverage-report
          path: coverage-report/
          retention-days: 30

      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results
          path: |
            target/debug/deps/*.xml
            test-reports/
          retention-days: 30

  # Performance validation against baseline
  performance_validation:
    name: Performance Validation
    needs: pre_validation
    if: needs.pre_validation.outputs.should_run_performance == 'true'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout current code
        uses: actions/checkout@v4
        with:
          path: current

      - name: Checkout baseline code
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.pre_validation.outputs.baseline_ref }}
          path: baseline

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Setup cache
        uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            current/target
            baseline/target
            test-cache
          key: performance-${{ hashFiles('**/Cargo.lock') }}

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential pkg-config hyperfine

      - name: Build baseline version
        working-directory: baseline
        run: |
          cargo build --release --all-features

      - name: Build current version
        working-directory: current
        run: |
          cargo build --release --all-features

      - name: Run performance benchmarks
        run: |
          mkdir -p performance-results

          # Run inference benchmarks
          cd current
          cargo bench --bench inference -- --output-format json > ../performance-results/current-inference.json

          cd ../baseline
          cargo bench --bench inference -- --output-format json > ../performance-results/baseline-inference.json

          cd ../current
          cargo bench --bench kernels -- --output-format json > ../performance-results/current-kernels.json

          cd ../baseline
          cargo bench --bench kernels -- --output-format json > ../performance-results/baseline-kernels.json

      - name: Compare performance results
        run: |
          cd current
          python3 scripts/compare_performance.py \
            ../performance-results/baseline-inference.json \
            ../performance-results/current-inference.json \
            ../performance-results/baseline-kernels.json \
            ../performance-results/current-kernels.json \
            --output ../performance-results/comparison.json \
            --threshold 0.95  # Allow 5% performance regression

      - name: Generate performance report
        run: |
          cd current
          python3 scripts/generate_performance_report.py \
            ../performance-results/comparison.json \
            --output ../performance-results/performance-report.html

      - name: Upload performance results
        uses: actions/upload-artifact@v3
        with:
          name: performance-results
          path: performance-results/
          retention-days: 30

  # Security and quality validation
  security_validation:
    name: Security and Quality Validation
    needs: pre_validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Setup cache
        uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: security-${{ hashFiles('**/Cargo.lock') }}

      - name: Install security tools
        run: |
          cargo install cargo-audit cargo-deny --locked

      - name: Run security audit
        run: |
          cargo audit --json > security-audit.json

      - name: Run dependency check
        run: |
          cargo deny check

      - name: Run clippy with strict lints
        run: |
          cargo clippy --all-features --workspace -- -D warnings -D clippy::all

      - name: Check code formatting
        run: |
          cargo fmt --all -- --check

      - name: Run unsafe code analysis
        run: |
          python3 scripts/analyze_unsafe.py > unsafe-analysis.json

      - name: Upload security results
        uses: actions/upload-artifact@v3
        with:
          name: security-results
          path: |
            security-audit.json
            unsafe-analysis.json
          retention-days: 30

  # Documentation and examples validation
  documentation_validation:
    name: Documentation Validation
    needs: pre_validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Setup cache
        uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: docs-${{ hashFiles('**/Cargo.lock') }}

      - name: Build documentation
        run: |
          cargo doc --all-features --workspace --no-deps

      - name: Test documentation examples
        run: |
          cargo test --doc --all-features --workspace

      - name: Run example programs
        run: |
          cargo run --example basic_inference --features default
          cargo run --example streaming_generation --features default

      - name: Validate README examples
        run: |
          python3 scripts/validate_readme_examples.py

      - name: Check documentation links
        run: |
          python3 scripts/check_doc_links.py

  # Release quality gates
  quality_gates:
    name: Release Quality Gates
    needs:
      [
        cross_platform_validation,
        comprehensive_testing,
        performance_validation,
        security_validation,
        documentation_validation,
      ]
    if: always()
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v3

      - name: Evaluate quality gates
        id: quality_gates
        run: |
          python3 scripts/evaluate_quality_gates.py \
            --coverage-report coverage-report/tarpaulin-report.json \
            --performance-report performance-results/comparison.json \
            --security-report security-results/security-audit.json \
            --cross-platform-results build-*/
        continue-on-error: true

      - name: Generate release validation report
        run: |
          python3 scripts/generate_release_report.py \
            --version "${{ github.event.inputs.release_candidate }}" \
            --baseline "${{ needs.pre_validation.outputs.baseline_ref }}" \
            --coverage-report coverage-report/tarpaulin-report.json \
            --performance-report performance-results/comparison.json \
            --security-report security-results/security-audit.json \
            --output release-validation-report.html

      - name: Upload release validation report
        uses: actions/upload-artifact@v3
        with:
          name: release-validation-report
          path: release-validation-report.html
          retention-days: 90

      - name: Create release validation summary
        run: |
          echo "# Release Validation Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Release Candidate:** ${{ github.event.inputs.release_candidate }}" >> $GITHUB_STEP_SUMMARY
          echo "**Baseline Version:** ${{ needs.pre_validation.outputs.baseline_ref }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.quality_gates.outcome }}" = "success" ]; then
            echo "✅ **All quality gates passed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The release candidate is ready for approval." >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Quality gates failed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The release candidate requires fixes before approval." >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Validation Results" >> $GITHUB_STEP_SUMMARY
          echo "- Cross-platform builds: ${{ needs.cross_platform_validation.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Comprehensive testing: ${{ needs.comprehensive_testing.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Performance validation: ${{ needs.performance_validation.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Security validation: ${{ needs.security_validation.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Documentation validation: ${{ needs.documentation_validation.result }}" >> $GITHUB_STEP_SUMMARY

      - name: Fail if quality gates not met
        if: steps.quality_gates.outcome != 'success'
        run: |
          echo "Release validation failed. Check the quality gates report for details."
          exit 1

  # Release approval workflow
  release_approval:
    name: Release Approval
    needs: quality_gates
    if: success()
    runs-on: ubuntu-latest
    environment: release-approval

    steps:
      - name: Request release approval
        uses: actions/github-script@v6
        with:
          script: |
            const { data: issue } = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Release Approval: ${{ github.event.inputs.release_candidate }}`,
              body: `
            ## Release Validation Complete ✅

            **Release Candidate:** ${{ github.event.inputs.release_candidate }}
            **Baseline Version:** ${{ needs.pre_validation.outputs.baseline_ref }}
            **Validation Run:** ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

            ### Validation Results
            - ✅ Cross-platform validation passed
            - ✅ Comprehensive test suite passed  
            - ✅ Performance validation passed
            - ✅ Security validation passed
            - ✅ Documentation validation passed
            - ✅ All quality gates met

            ### Next Steps
            1. Review the [validation report](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            2. Approve this issue to proceed with release
            3. The release will be automatically created upon approval

            **Approvers:** @maintainer-team
            `,
              labels: ['release', 'approval-required']
            });

            console.log(`Created approval issue: ${issue.html_url}`);

      - name: Wait for approval
        run: |
          echo "Release validation complete. Waiting for manual approval."
          echo "An approval issue has been created for maintainer review."
