# How-To: Verifying Receipt Honesty and Kernel Paths

**Problem-oriented** | **Goal: Validate inference receipts accurately reflect computation paths**

This guide shows you how to verify BitNet-rs inference receipts to ensure they honestly represent the actual computation paths used. Receipt verification is essential for trusting performance baselines, detecting silent fallbacks, and auditing production deployments.

## Prerequisites

- Completed inference run that generated a receipt (`ci/inference.json`)
- Understanding of receipt structure (see `crates/bitnet-inference/src/receipts.rs`)
- Familiarity with BitNet-rs quantization types (I2S, TL1, TL2)

## Problem Statement

**Why receipt verification matters:**

Inference receipts claim specific computation paths and performance metrics. Without validation, these claims can be misleading:

- **False claim:** `"compute_path": "real"` with `"kernels": ["dequant_fp32", "fp32_matmul"]`
  - Reality: Used FP32 fallback, not quantized computation
  - Impact: Performance baseline is incorrect

- **Silent fallback:** GPU receipt shows `"backend": "cuda"` but kernels are CPU
  - Reality: GPU OOM caused silent fallback to CPU
  - Impact: Production deployment expects 80 tok/s, gets 15 tok/s

Receipt verification prevents these scenarios by correlating claims with evidence.

## Task 1: Basic Receipt Validation

**Goal:** Verify a receipt passes schema validation and basic honesty checks.

### Step-by-Step

```bash
# 1. Run inference to generate receipt
cargo run -p xtask -- benchmark \
  --model models/bitnet-model.gguf \
  --tokens 128

# Receipt written to: ci/inference.json

# 2. Verify receipt schema and basic claims
cargo run -p xtask -- verify-receipt ci/inference.json

# Expected output:
# ✓ Schema version: 1.0.0 (valid)
# ✓ Required fields present: backend, compute_path, kernels, tokens_per_second
# ✓ Compute path: real (valid)
# ✓ Backend: cpu (valid)
# ✓ Kernel count: 3 kernels
# ✓ Tokens generated: 128 (matches requested)
# ✓ Receipt validation: PASS
```

### Success Criteria

✓ Schema version is valid (`1.0.0` or compatible)
✓ All required fields present
✓ `compute_path` is either `"real"` or `"fallback"` (not `"mock"`)
✓ Kernel array is non-empty
✓ Performance metrics are realistic (not suspiciously high)

### Common Issues

**Issue: Schema validation fails**
```bash
# Error: "Unknown schema version: 0.9.0"
# Solution: Update BitNet-rs to support schema version

cargo update -p bitnet-common
cargo build --no-default-features --release --features cpu
```

**Issue: Missing required fields**
```bash
# Error: "Required field 'compute_path' missing"
# Solution: Receipt was generated by older version

# Check BitNet-rs version
cargo tree | grep bitnet-inference

# Update to version with Issue #453 support (v0.1.0+)
```

## Task 2: Validate Kernel IDs Match Claimed Computation Path

**Goal:** Verify kernel IDs correlate with `compute_path` claim.

### Quantized Kernel ID Patterns

BitNet-rs uses consistent kernel naming conventions:

| Quantization Type | Device | Kernel ID Patterns | Examples |
|-------------------|--------|-------------------|----------|
| **I2S** | GPU | `gemm_*`, `i2s_gpu_*`, `wmma_*` | `gemm_fp16`, `i2s_gpu_quantize`, `wmma_matmul` |
| **I2S** | CPU | `i2s_gemv`, `i2s_matmul_*`, `quantized_matmul_i2s` | `i2s_gemv`, `quantized_matmul_i2s` |
| **TL1** | CPU (ARM) | `tl1_neon_*`, `tl1_lookup_*` | `tl1_neon_matmul`, `tl1_lookup` |
| **TL2** | CPU (x86) | `tl2_avx_*`, `tl2_avx512_*` | `tl2_avx_matmul`, `tl2_avx512_pack` |

### Fallback Kernel ID Patterns

Fallback kernels indicate FP32 dequantization:

| Pattern | Meaning | Example |
|---------|---------|---------|
| `dequant_*` | Dequantization to FP32 | `dequant_fp32`, `dequant_i2s_to_fp32` |
| `fp32_*` | FP32 computation | `fp32_matmul`, `fp32_gemm` |
| `fallback_*` | Generic fallback path | `fallback_compute`, `fallback_matmul` |
| `scalar_*` | Scalar (non-SIMD) fallback | `scalar_matmul`, `scalar_quantization` |
| `mock_*` | Mock/test stub | `mock_kernel`, `mock_inference` |

### Verification Commands

```bash
# Extract kernel IDs from receipt
cat ci/inference.json | jq '.kernels[]'

# Example output (quantized computation):
"i2s_gemv"
"quantized_matmul_i2s"

# Check for quantized kernel patterns
cat ci/inference.json | jq '.kernels[] | select(
  contains("i2s_") or
  contains("tl1_") or
  contains("tl2_") or
  contains("gemm_") or
  contains("wmma_")
)'

# Check for fallback patterns (should be empty for "real" compute_path)
cat ci/inference.json | jq '.kernels[] | select(
  contains("dequant") or
  contains("fp32_") or
  contains("fallback_") or
  contains("scalar_") or
  contains("mock_")
)'
```

### Automated Verification

```bash
# Use verify-receipt with --require-quantized-kernels flag
cargo run -p xtask -- verify-receipt --require-quantized-kernels ci/inference.json

# This performs:
# 1. Schema validation
# 2. Kernel ID pattern matching
# 3. Compute path correlation check
# 4. Fallback detection

# Expected output (success):
# ✓ Schema validation: PASS
# ✓ Kernel validation: 2 quantized kernels detected
#   - i2s_gemv (CPU quantized matmul)
#   - quantized_matmul_i2s (CPU quantized matmul)
# ✓ Compute path validation: "real" correlates with quantized kernels
# ✓ Fallback detection: No fallback indicators found
# ✓ Receipt validation: PASS
```

### Success Criteria

✓ `compute_path="real"` receipts have ≥1 quantized kernel ID
✓ No fallback indicators in quantized receipts
✓ GPU receipts (`backend="cuda"`) have GPU kernel IDs
✓ CPU receipts have CPU kernel IDs matching architecture

## Task 3: Verify GPU vs CPU Kernel Paths

**Goal:** Ensure GPU claims are backed by actual GPU kernels.

### GPU Receipt Validation

```bash
# Check GPU receipt structure
cat ci/inference.json | jq '{
  backend,
  compute_path,
  kernels,
  tokens_per_second
}'

# Expected for genuine GPU inference:
{
  "backend": "cuda",
  "compute_path": "real",
  "kernels": [
    "gemm_fp16",        # GPU mixed precision matmul
    "i2s_gpu_quantize", # GPU quantization kernel
    "wmma_matmul"       # Tensor Core acceleration
  ],
  "tokens_per_second": 87.5  # GPU-level performance
}

# Verify GPU kernel enforcement
cargo run -p xtask -- verify-receipt --require-gpu-kernels ci/inference.json
```

### Detect Silent CPU Fallback

**Symptom:** Receipt claims GPU but has CPU kernels

```bash
# Example silent fallback receipt:
{
  "backend": "cuda",  # ← Claims GPU
  "compute_path": "real",
  "kernels": [
    "i2s_gemv",           # ← CPU kernel!
    "quantized_matmul_i2s" # ← CPU kernel!
  ],
  "tokens_per_second": 15.2  # ← CPU-level performance
}

# verify-receipt will detect this:
cargo run -p xtask -- verify-receipt --require-gpu-kernels ci/inference.json

# Output:
✗ GPU kernel validation: FAIL
Error: Receipt claims backend="cuda" but no GPU kernels detected
Found CPU kernels: ["i2s_gemv", "quantized_matmul_i2s"]

This indicates silent fallback from GPU to CPU occurred.
Possible causes:
  - GPU out of memory (check nvidia-smi)
  - CUDA runtime error during inference
  - Device mismatch (model on GPU, inference on CPU)
```

### Success Criteria

✓ GPU receipts have GPU kernel IDs (not CPU)
✓ Performance metrics match GPU baseline (50-100 tok/s)
✓ `verify-receipt --require-gpu-kernels` passes

## Task 4: Validate Performance Metrics for Realism

**Goal:** Detect suspiciously high performance that indicates mock inference.

### Performance Baselines

**Realistic performance ranges:**

| Configuration | Expected TPS | Suspicious if > |
|---------------|--------------|-----------------|
| CPU I2S | 10-20 tok/s | 40 tok/s |
| CPU TL1 (ARM NEON) | 12-18 tok/s | 35 tok/s |
| CPU TL2 (x86 AVX) | 10-15 tok/s | 30 tok/s |
| GPU I2S (FP16) | 50-100 tok/s | 150 tok/s |
| GPU I2S (BF16) | 60-110 tok/s | 180 tok/s |

### Validation Commands

```bash
# Check performance metrics
cat ci/inference.json | jq '{
  tokens_per_second,
  tokens_generated,
  backend,
  kernels: (.kernels | length)
}'

# Example output:
{
  "tokens_per_second": 18.5,    # ← Realistic for CPU I2S
  "tokens_generated": 128,
  "backend": "cpu",
  "kernels": 2
}

# Automated performance validation
cargo run -p xtask -- verify-receipt --validate-performance ci/inference.json
```

### Detect Mock Inference

**Symptom:** Unrealistic performance (>150 tok/s)

```bash
# Example mock inference receipt:
{
  "compute_path": "real",
  "backend": "cpu",
  "kernels": ["i2s_gemv"],
  "tokens_per_second": 250.0  # ← Suspiciously high!
}

# verify-receipt will flag this:
cargo run -p xtask -- verify-receipt --validate-performance ci/inference.json

# Output:
✗ Performance validation: FAIL
Error: Suspicious performance detected: 250.0 tok/s (threshold: 150.0)

CPU inference claiming 250 tok/s is unrealistic. This suggests:
  - Mock inference path was used
  - Performance measurement error
  - Caching artifacts (not real generation)

Recommendation: Re-run with BITNET_STRICT_MODE=1 to ensure real inference
```

### Success Criteria

✓ Performance within expected range for device and quantization type
✓ Not flagged by `--validate-performance` check
✓ Consistent across multiple runs (deterministic mode)

## Task 5: Cross-Validate Receipts from Multiple Runs

**Goal:** Ensure receipts are consistent across deterministic runs.

### Deterministic Receipt Validation

```bash
# Run inference twice with deterministic settings
export BITNET_DETERMINISTIC=1
export BITNET_SEED=42
export RAYON_NUM_THREADS=1
export BITNET_STRICT_MODE=1

# Run 1
cargo run -p xtask -- benchmark --model models/bitnet-model.gguf --tokens 128
cp ci/inference.json ci/receipts/run1.json

# Run 2
cargo run -p xtask -- benchmark --model models/bitnet-model.gguf --tokens 128
cp ci/inference.json ci/receipts/run2.json

# Compare receipts
diff <(jq -S . ci/receipts/run1.json) <(jq -S . ci/receipts/run2.json)

# Expected: Only timestamps differ
# Actual kernel IDs, compute_path, tokens_per_second should be identical
```

### Validation Script

```bash
#!/bin/bash
# scripts/cross-validate-receipts.sh
set -euo pipefail

export BITNET_DETERMINISTIC=1
export BITNET_SEED=42
export RAYON_NUM_THREADS=1
export BITNET_STRICT_MODE=1

MODEL="${1:-models/bitnet-model.gguf}"
RUNS="${2:-5}"

echo "Running $RUNS deterministic inference runs..."

for i in $(seq 1 $RUNS); do
  echo "Run $i/$RUNS"
  cargo run -p xtask -- benchmark --model "$MODEL" --tokens 128 --quiet
  cp ci/inference.json "ci/receipts/run$i.json"
done

echo "Cross-validating receipts..."

# Extract key fields for comparison
for i in $(seq 1 $RUNS); do
  jq '{
    compute_path,
    backend,
    kernels,
    tokens_generated
  }' "ci/receipts/run$i.json" > "ci/receipts/run$i-key-fields.json"
done

# Compare all runs against run1
for i in $(seq 2 $RUNS); do
  if ! diff -q ci/receipts/run1-key-fields.json "ci/receipts/run$i-key-fields.json" > /dev/null; then
    echo "✗ Run $i differs from run 1"
    diff ci/receipts/run1-key-fields.json "ci/receipts/run$i-key-fields.json"
    exit 1
  else
    echo "✓ Run $i matches run 1"
  fi
done

echo "✓ All $RUNS runs produce identical receipts (deterministic)"
```

### Success Criteria

✓ All runs produce identical `compute_path`, `backend`, `kernels`
✓ `tokens_generated` is identical
✓ `tokens_per_second` variance <5% (some variation is normal)
✓ No runs show fallback indicators

## Task 6: Audit Historical Receipts for Regressions

**Goal:** Detect performance regressions or fallback introductions over time.

### Historical Receipt Analysis

```bash
# Collect historical receipts from CI artifacts
ls -lt ci/receipts/*.json | head -20

# Extract performance trends
jq -s '[.[] | {
  date: .timestamp,
  tps: .tokens_per_second,
  compute_path: .compute_path,
  kernels: (.kernels | length)
}]' ci/receipts/*.json > ci/performance-history.json

# Detect regressions
jq 'group_by(.compute_path) | map({
  compute_path: .[0].compute_path,
  mean_tps: (map(.tps) | add / length),
  min_tps: (map(.tps) | min),
  max_tps: (map(.tps) | max)
})' ci/performance-history.json

# Example output:
[
  {
    "compute_path": "real",
    "mean_tps": 18.3,
    "min_tps": 17.8,  # ← Regression if significantly lower than historical
    "max_tps": 18.9
  }
]
```

### Detect Fallback Introduction

```bash
# Check if fallback kernels appeared in recent commits
for receipt in ci/receipts/commit-*.json; do
  commit_hash=$(basename "$receipt" .json | cut -d- -f2)

  if jq -e '.kernels[] | select(
    contains("dequant") or
    contains("fp32_") or
    contains("fallback_")
  )' "$receipt" > /dev/null; then
    echo "⚠️  Fallback detected in commit $commit_hash"
    git show --oneline --no-patch "$commit_hash"
  fi
done
```

### Success Criteria

✓ No performance regressions >10% from baseline
✓ No fallback kernel introductions in recent commits
✓ Compute path remains `"real"` across all historical receipts
✓ Kernel count stable (not decreasing)

## Task 7: Receipt Validation in CI/CD Pipelines

**Goal:** Automate receipt verification in continuous integration.

### GitHub Actions Example

```yaml
# .github/workflows/receipt-validation.yml
name: Receipt Validation

on:
  pull_request:
  push:
    branches: [main, develop]

jobs:
  validate-receipts:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Build BitNet-rs
        run: cargo build --no-default-features --release --features cpu

      - name: Run benchmark with strict mode
        env:
          BITNET_STRICT_MODE: "1"
          BITNET_DETERMINISTIC: "1"
          BITNET_SEED: "42"
          RAYON_NUM_THREADS: "1"
        run: |
          cargo run -p xtask -- benchmark \
            --model tests/fixtures/mini.gguf \
            --tokens 128

      - name: Verify receipt schema
        run: cargo run -p xtask -- verify-receipt ci/inference.json

      - name: Verify quantized kernels
        run: cargo run -p xtask -- verify-receipt --require-quantized-kernels ci/inference.json

      - name: Verify performance metrics
        run: cargo run -p xtask -- verify-receipt --validate-performance ci/inference.json

      - name: Check for fallback indicators
        run: |
          if jq -e '.kernels[] | select(contains("dequant") or contains("fp32_") or contains("fallback_"))' ci/inference.json; then
            echo "ERROR: Fallback kernels detected"
            exit 1
          fi

      - name: Upload receipt artifact
        uses: actions/upload-artifact@v4
        with:
          name: inference-receipt
          path: ci/inference.json
```

### Success Criteria

✓ CI pipeline runs receipt verification on every PR
✓ All verification checks must pass before merge
✓ Receipts saved as artifacts for historical analysis
✓ Fallback detection prevents regression introduction

## Best Practices

1. **Always verify receipts after establishing baselines:**
   ```bash
   cargo run -p xtask -- benchmark --model model.gguf --tokens 128
   cargo run -p xtask -- verify-receipt ci/inference.json
   ```

2. **Use strict mode when generating receipts:**
   ```bash
   BITNET_STRICT_MODE=1 cargo run -p xtask -- benchmark --model model.gguf
   ```

3. **Save receipts with meaningful names:**
   ```bash
   cp ci/inference.json ci/receipts/cpu-i2s-$(date +%Y%m%d-%H%M%S).json
   ```

4. **Automate receipt validation in CI/CD:**
   - Prevents regressions
   - Catches fallback introductions early
   - Maintains honest performance baselines

5. **Cross-validate deterministic runs:**
   ```bash
   # Ensure receipts are consistent
   scripts/cross-validate-receipts.sh models/bitnet-model.gguf 5
   ```

## Related Documentation

- **Tutorial:** [Getting Started with Strict Mode](../tutorials/strict-mode-quantization-validation.md)
- **How-To:** [Running Strict Mode Validation Workflows](./strict-mode-validation-workflows.md)
- **Reference:** [Quantization Support](../reference/quantization-support.md#strict-quantization-guards-issue-453)
- **Reference:** [Validation Gates](../reference/validation-gates.md#receipt-honesty-validation)

## Summary

This guide covered seven receipt verification tasks:

✓ **Basic validation:** Schema and field presence checks
✓ **Kernel ID validation:** Ensure quantized kernel patterns match claims
✓ **GPU/CPU validation:** Verify device-specific kernel usage
✓ **Performance validation:** Detect suspiciously high/low metrics
✓ **Cross-validation:** Ensure deterministic receipts are identical
✓ **Historical analysis:** Track performance and detect regressions
✓ **CI/CD integration:** Automate verification in pipelines

Receipt verification ensures BitNet-rs inference receipts honestly represent actual computation paths, enabling trustworthy performance baselines and confident production deployments.
