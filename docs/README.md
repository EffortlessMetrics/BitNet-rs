# BitNet.rs Documentation

Welcome to the comprehensive documentation for BitNet.rs, the production-ready Rust implementation of BitNet 1-bit Large Language Model inference.

## Quick Navigation

### Getting Started
- **[Getting Started Guide](getting-started.md)** - Installation, basic usage, and quick start examples
- **[API Reference](reference/api-reference.md)** - Complete API documentation with examples
- **[Migration Guide](migration-guide.md)** - Migrate from Python/C++ BitNet implementations

### Configuration & Testing
- **[Configuration layering and clamps](./configuration.md)** - How the manager, environment overlay, and context clamps interact
- **[Testing guidelines](./testing.md)** - Writing stable, non-flaky tests

### Architecture
- **[ADR-0001: Configuration layering and clamp location](./adr/0001-configuration-layering.md)** - Architectural decision record

### Guides
- **[Performance Tuning](performance-tuning.md)** - Optimize performance for your hardware and use case
- **[Troubleshooting](troubleshooting/troubleshooting.md)** - Common issues and solutions

### Examples
- **[Basic Examples](../examples/basic/)** - Simple usage patterns
- **[Advanced Examples](../examples/advanced/)** - Complex integration scenarios
- **[Web Integration](../examples/web/)** - Web service and browser examples

## Documentation Overview

### Core Concepts

BitNet.rs is built around several key concepts:

- **Models**: BitNet model implementations with 1-bit quantization support
- **Inference Engines**: High-performance inference with CPU/GPU acceleration
- **Quantization**: Efficient 1-bit model compression with multiple backends
- **Streaming**: Real-time text generation with async/await support
- **Cross-Validation**: Optional compatibility testing with legacy C++ implementation
- **Device Abstraction**: Unified interface for CPU, CUDA, and Metal backends

### Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Applications  ‚îÇ    ‚îÇ   Bindings      ‚îÇ    ‚îÇ   Interfaces    ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ CLI Tool      ‚îÇ    ‚îÇ ‚Ä¢ Python (PyO3) ‚îÇ    ‚îÇ ‚Ä¢ C API         ‚îÇ
‚îÇ ‚Ä¢ Web Services  ‚îÇ    ‚îÇ ‚Ä¢ JavaScript    ‚îÇ    ‚îÇ ‚Ä¢ WebAssembly   ‚îÇ
‚îÇ ‚Ä¢ Desktop Apps  ‚îÇ    ‚îÇ ‚Ä¢ Rust Native   ‚îÇ    ‚îÇ ‚Ä¢ REST API      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        BitNet Rust Core                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ Inference       ‚îÇ  ‚îÇ Models          ‚îÇ  ‚îÇ Quantization    ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ CPU Engine    ‚îÇ  ‚îÇ ‚Ä¢ BitNet        ‚îÇ  ‚îÇ ‚Ä¢ I2S           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ GPU Engine    ‚îÇ  ‚îÇ ‚Ä¢ Transformers  ‚îÇ  ‚îÇ ‚Ä¢ TL1/TL2       ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Streaming     ‚îÇ  ‚îÇ ‚Ä¢ Model Loading ‚îÇ  ‚îÇ ‚Ä¢ Dynamic       ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ Kernels         ‚îÇ  ‚îÇ Memory          ‚îÇ  ‚îÇ Device          ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ SIMD (CPU)    ‚îÇ  ‚îÇ ‚Ä¢ Allocators    ‚îÇ  ‚îÇ ‚Ä¢ CPU           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ CUDA (GPU)    ‚îÇ  ‚îÇ ‚Ä¢ KV Cache      ‚îÇ  ‚îÇ ‚Ä¢ CUDA          ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚Ä¢ Metal (macOS) ‚îÇ  ‚îÇ ‚Ä¢ Memory Pool   ‚îÇ  ‚îÇ ‚Ä¢ Metal         ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Feature Matrix

| Feature | Status | Documentation |
|---------|--------|---------------|
| **Core Inference** | ‚úÖ Complete | [API Reference](reference/api-reference.md#bitnetmodel) |
| **Streaming Generation** | ‚úÖ Complete | [Getting Started](getting-started.md#streaming-generation) |
| **CPU Optimization** | ‚úÖ Complete | [Performance Tuning](performance-tuning.md#cpu-optimization) |
| **CUDA GPU Support** | ‚úÖ Complete | [Performance Tuning](performance-tuning.md#gpu-optimization) |
| **Metal GPU Support** | ‚úÖ Complete | [Troubleshooting](troubleshooting/troubleshooting.md#metal-gpu-issues) |
| **Quantization (I2S)** | ‚úÖ Complete | [API Reference](reference/api-reference.md#quantization) |
| **Quantization (TL1/TL2)** | ‚úÖ Complete | [API Reference](reference/api-reference.md#quantization) |
| **Python Bindings** | ‚úÖ Complete | [Migration Guide](migration-guide.md#migrating-from-python-bitnet) |
| **C API** | ‚úÖ Complete | [Migration Guide](migration-guide.md#migrating-from-c-bitnet) |
| **WebAssembly** | ‚úÖ Complete | [Examples](../examples/wasm/) |
| **CLI Tool** | ‚úÖ Complete | [Getting Started](getting-started.md#using-the-cli) |

## Quick Start

### Installation

```bash
# Install CLI tool
cargo install bitnet-cli

# Or add to your Rust project
cargo add bitnet
```

### Basic Usage

```rust
use bitnet::{BitNetModel, GenerationConfig};

#[tokio::main]
async fn main() -> bitnet::Result<()> {
    // Load model
    let model = BitNetModel::from_pretrained("microsoft/bitnet-b1_58-large").await?;
    
    // Generate text
    let output = model.generate("Hello, world!", &GenerationConfig::default()).await?;
    println!("Generated: {}", output);
    
    Ok(())
}
```

### CLI Usage

```bash
# Download and run inference
bitnet-cli model download microsoft/bitnet-b1_58-large
bitnet-cli inference --model microsoft/bitnet-b1_58-large --prompt "Hello, world!"
```

## Performance

BitNet.rs delivers significant performance improvements over existing implementations:

| Metric | Original C++ | BitNet.rs | Improvement |
|--------|--------------|-----------|-------------|
| **Inference Speed** | 520 tok/s | 1,250 tok/s | **2.4x faster** |
| **Memory Usage** | 3.2 GB | 2.1 GB | **34% less** |
| **Model Loading** | 2.1s | 0.8s | **2.6x faster** |
| **Binary Size** | 45 MB | 12 MB | **73% smaller** |
| **Build Time** | 7min | 45s | **9.3x faster** |

*Benchmarks include cached dependencies and optimized build system.*

See [Performance Guide](performance-guide.md) for optimization guidelines.

## Supported Platforms

| Platform | CPU | GPU | Status |
|----------|-----|-----|--------|
| **Linux x86_64** | ‚úÖ SIMD (AVX2/AVX-512) | ‚úÖ CUDA | Fully Supported |
| **Linux ARM64** | ‚úÖ SIMD (NEON) | ‚ùå | Fully Supported |
| **Windows x86_64** | ‚úÖ SIMD (AVX2/AVX-512) | ‚úÖ CUDA | Fully Supported |
| **macOS Intel** | ‚úÖ SIMD (AVX2) | ‚úÖ Metal | Fully Supported |
| **macOS Apple Silicon** | ‚úÖ SIMD (NEON) | ‚úÖ Metal | Fully Supported |
| **WebAssembly** | ‚úÖ Basic | ‚ùå | Supported |

## Model Support

BitNet Rust supports multiple model formats and architectures:

### Formats
- **GGUF** - Optimized format with quantization support
- **SafeTensors** - Safe tensor format from HuggingFace
- **HuggingFace Hub** - Direct download and loading

### Quantization
- **I2S** - 2-bit signed quantization (universal)
- **TL1** - Table lookup quantization (ARM optimized)
- **TL2** - Table lookup quantization (x86 optimized)
- **Dynamic** - Runtime quantization

### Models
- BitNet b1.58 (all sizes)
- Custom BitNet architectures
- Compatible transformer models

## Language Bindings

BitNet Rust provides bindings for multiple languages:

### Python
```python
import bitnet

model = bitnet.BitNetModel.from_pretrained("microsoft/bitnet-b1_58-large")
output = model.generate("Hello, world!")
```

### JavaScript/WebAssembly
```javascript
import { BitNetModel } from 'bitnet-wasm';

const model = await BitNetModel.fromPretrained("microsoft/bitnet-b1_58-large");
const output = await model.generate("Hello, world!");
```

### C/C++
```c
#include "bitnet_c.h"

BitNetModel* model = bitnet_model_load("model.gguf");
char* output = bitnet_inference(model, "Hello, world!", 100, 0.7f);
```

## Community and Support

### Getting Help
- **GitHub Issues**: [Report bugs and request features](https://github.com/microsoft/BitNet/issues)
- **Documentation**: [Complete documentation](https://docs.rs/bitnet)
- **Examples**: Working code samples in [examples/](../examples/) directory

### Contributing
- **Contributing Guide**: [How to contribute](../CONTRIBUTING.md)
- **Code of Conduct**: [Community guidelines](../CODE_OF_CONDUCT.md)
- **Development Setup**: [Set up development environment](development.md)

### Professional Support
For commercial support and services related to BitNet.rs, please contact Microsoft through official channels.

## Roadmap

### Current Release (v0.1.0)
- ‚úÖ Core inference engine
- ‚úÖ CPU/GPU optimization
- ‚úÖ Quantization support
- ‚úÖ CLI tool
- ‚úÖ C API

### Next Release (v0.2.0)
- üöß Python bindings completion
- üöß WebAssembly optimization
- üöß Advanced batching
- üöß Model parallelism

### Future Releases
- üìã Distributed inference
- üìã Custom model architectures
- üìã Advanced quantization methods
- üìã Mobile deployment

## License

BitNet Rust is licensed under the [MIT License](../LICENSE).

## Acknowledgments

- Original BitNet research and implementation teams
- Rust community for excellent tooling and libraries
- Contributors and early adopters

---

**Need help?** Check our [Troubleshooting Guide](troubleshooting/troubleshooting.md) or [open an issue](https://github.com/microsoft/BitNet/issues) on GitHub.