# [SIMULATION] conv2d uses naive nested loops instead of optimized convolution algorithms

## Problem Description

The `conv2d` function in `convolution.rs` implements convolution using simple nested loops, resulting in poor performance compared to optimized algorithms like GEMM-based, FFT-based, or Winograd convolution, severely limiting the efficiency of convolutional operations.

## Environment

**File**: `crates/bitnet-kernels/src/convolution.rs`
**Component**: 2D Convolution Kernel Implementation
**Issue Type**: Simulation / Unoptimized Algorithm

## Root Cause Analysis

**Current Implementation:**
```rust
pub fn conv2d(
    input: &[f32],
    weight: &[f32],
    bias: Option<&[f32]>,
    output: &mut [f32],
    params: Conv2DParams,
    input_dims: (usize, usize, usize, usize),
    weight_dims: (usize, usize, usize, usize),
) -> Result<()> {
    // Perform convolution with nested loops
    for batch in 0..n {
        for out_ch in 0..oc {
            for in_ch in 0..ic {
                for y in 0..oh {
                    for x in 0..ow {
                        // Nested loop convolution computation
                        for ky in 0..kh {
                            for kx in 0..kw {
                                // Direct convolution computation
                            }
                        }
                    }
                }
            }
        }
    }
    Ok(())
}
```

**Analysis:**
1. **O(n‚Å∑) Complexity**: Seven nested loops create extremely poor computational complexity
2. **No SIMD Utilization**: Scalar operations miss vectorization opportunities
3. **Poor Cache Locality**: Memory access patterns are not optimized for modern CPUs
4. **Missing Optimization Strategies**: No use of GEMM, FFT, or Winograd algorithms

## Impact Assessment

**Severity**: High
**Affected Areas**:
- Convolutional neural network performance
- Inference speed for vision models
- Training efficiency
- GPU utilization potential

**Performance Impact**:
- 10-100x slower than optimized implementations
- Poor scalability with larger models
- Inefficient resource utilization
- Uncompetitive inference performance

**Business Impact**:
- Non-viable for production CNN workloads
- Poor user experience with vision models
- Reduced competitiveness against optimized frameworks

## Proposed Solution

### Multi-Strategy Optimized Convolution Implementation

```rust
use rayon::prelude::*;

#[derive(Debug, Clone, Copy)]
pub enum ConvolutionStrategy {
    /// GEMM-based convolution (good for most cases)
    GEMM,
    /// FFT-based convolution (good for large kernels)
    FFT,
    /// Winograd convolution (good for small kernels)
    Winograd,
    /// Direct convolution with SIMD (fallback)
    DirectSIMD,
}

pub struct OptimizedConv2D {
    strategy_selector: StrategySelector,
    gemm_engine: GEMMEngine,
    fft_engine: Option<FFTEngine>,
    winograd_engine: Option<WinogradEngine>,
    simd_engine: SIMDEngine,
}

impl OptimizedConv2D {
    pub fn new() -> Result<Self> {
        Ok(Self {
            strategy_selector: StrategySelector::new(),
            gemm_engine: GEMMEngine::new()?,
            fft_engine: FFTEngine::new().ok(),
            winograd_engine: WinogradEngine::new().ok(),
            simd_engine: SIMDEngine::new(),
        })
    }

    pub fn conv2d(
        &self,
        input: &[f32],
        weight: &[f32],
        bias: Option<&[f32]>,
        output: &mut [f32],
        params: Conv2DParams,
        input_dims: (usize, usize, usize, usize),
        weight_dims: (usize, usize, usize, usize),
    ) -> Result<()> {
        // Select optimal strategy based on parameters
        let strategy = self.strategy_selector.select_strategy(
            &params, input_dims, weight_dims
        );

        match strategy {
            ConvolutionStrategy::GEMM => {
                self.conv2d_gemm(input, weight, bias, output, params, input_dims, weight_dims)
            }
            ConvolutionStrategy::FFT => {
                self.conv2d_fft(input, weight, bias, output, params, input_dims, weight_dims)
            }
            ConvolutionStrategy::Winograd => {
                self.conv2d_winograd(input, weight, bias, output, params, input_dims, weight_dims)
            }
            ConvolutionStrategy::DirectSIMD => {
                self.conv2d_direct_simd(input, weight, bias, output, params, input_dims, weight_dims)
            }
        }
    }

    fn conv2d_gemm(
        &self,
        input: &[f32],
        weight: &[f32],
        bias: Option<&[f32]>,
        output: &mut [f32],
        params: Conv2DParams,
        input_dims: (usize, usize, usize, usize),
        weight_dims: (usize, usize, usize, usize),
    ) -> Result<()> {
        let (n, ic, ih, iw) = input_dims;
        let (oc, _, kh, kw) = weight_dims;
        let oh = (ih + 2 * params.padding - kh) / params.stride + 1;
        let ow = (iw + 2 * params.padding - kw) / params.stride + 1;

        // Im2col transformation to convert convolution to GEMM
        let im2col_size = n * oh * ow * ic * kh * kw;
        let mut im2col_data = vec![0.0f32; im2col_size];

        self.im2col_transform(
            input, &mut im2col_data,
            input_dims, params, oh, ow
        )?;

        // Reshape for GEMM: (N*OH*OW, IC*KH*KW) x (IC*KH*KW, OC) = (N*OH*OW, OC)
        let m = n * oh * ow;
        let k = ic * kh * kw;
        let n_gemm = oc;

        // Perform optimized GEMM
        self.gemm_engine.sgemm(
            false, false, // No transpose
            m, n_gemm, k,
            1.0, // alpha
            &im2col_data, k,
            weight, n_gemm,
            0.0, // beta
            output, n_gemm,
        )?;

        // Add bias if present
        if let Some(bias_data) = bias {
            self.add_bias(output, bias_data, n, oc, oh, ow)?;
        }

        Ok(())
    }

    fn im2col_transform(
        &self,
        input: &[f32],
        im2col_output: &mut [f32],
        input_dims: (usize, usize, usize, usize),
        params: Conv2DParams,
        oh: usize,
        ow: usize,
    ) -> Result<()> {
        let (n, ic, ih, iw) = input_dims;
        let kh = params.kernel_size;
        let kw = params.kernel_size;

        // Parallel im2col transformation
        im2col_output.par_chunks_mut(ic * kh * kw)
            .enumerate()
            .for_each(|(idx, chunk)| {
                let batch = idx / (oh * ow);
                let spatial_idx = idx % (oh * ow);
                let out_y = spatial_idx / ow;
                let out_x = spatial_idx % ow;

                let mut col_idx = 0;
                for in_ch in 0..ic {
                    for ky in 0..kh {
                        for kx in 0..kw {
                            let in_y = out_y * params.stride + ky;
                            let in_x = out_x * params.stride + kx;

                            let value = if in_y >= params.padding &&
                                         in_x >= params.padding &&
                                         in_y < ih + params.padding &&
                                         in_x < iw + params.padding {
                                let actual_y = in_y - params.padding;
                                let actual_x = in_x - params.padding;
                                let input_idx = ((batch * ic + in_ch) * ih + actual_y) * iw + actual_x;
                                input[input_idx]
                            } else {
                                0.0 // Padding
                            };

                            chunk[col_idx] = value;
                            col_idx += 1;
                        }
                    }
                }
            });

        Ok(())
    }

    fn conv2d_winograd(
        &self,
        input: &[f32],
        weight: &[f32],
        bias: Option<&[f32]>,
        output: &mut [f32],
        params: Conv2DParams,
        input_dims: (usize, usize, usize, usize),
        weight_dims: (usize, usize, usize, usize),
    ) -> Result<()> {
        // Winograd F(2x2, 3x3) implementation for 3x3 kernels
        if params.kernel_size != 3 || params.stride != 1 {
            return Err(anyhow::anyhow!("Winograd only supports 3x3 kernels with stride 1"));
        }

        let winograd_engine = self.winograd_engine.as_ref()
            .ok_or_else(|| anyhow::anyhow!("Winograd engine not available"))?;

        winograd_engine.conv2d_f2x2_3x3(
            input, weight, bias, output,
            input_dims, weight_dims
        )
    }

    fn conv2d_direct_simd(
        &self,
        input: &[f32],
        weight: &[f32],
        bias: Option<&[f32]>,
        output: &mut [f32],
        params: Conv2DParams,
        input_dims: (usize, usize, usize, usize),
        weight_dims: (usize, usize, usize, usize),
    ) -> Result<()> {
        // Optimized direct convolution with SIMD
        self.simd_engine.conv2d_direct(
            input, weight, bias, output,
            params, input_dims, weight_dims
        )
    }
}

struct StrategySelector;

impl StrategySelector {
    fn new() -> Self {
        Self
    }

    fn select_strategy(
        &self,
        params: &Conv2DParams,
        input_dims: (usize, usize, usize, usize),
        weight_dims: (usize, usize, usize, usize),
    ) -> ConvolutionStrategy {
        let (_, ic, ih, iw) = input_dims;
        let (oc, _, kh, kw) = weight_dims;

        // Strategy selection heuristics
        if kh == 3 && kw == 3 && params.stride == 1 && params.padding == 1 {
            // Winograd is optimal for 3x3 convolutions
            return ConvolutionStrategy::Winograd;
        }

        if kh >= 7 || kw >= 7 {
            // FFT becomes beneficial for large kernels
            return ConvolutionStrategy::FFT;
        }

        // GEMM is generally good for most cases
        ConvolutionStrategy::GEMM
    }
}

struct GEMMEngine {
    // Integration with optimized BLAS library
}

impl GEMMEngine {
    fn new() -> Result<Self> {
        Ok(Self {})
    }

    fn sgemm(
        &self,
        trans_a: bool,
        trans_b: bool,
        m: usize,
        n: usize,
        k: usize,
        alpha: f32,
        a: &[f32],
        lda: usize,
        b: &[f32],
        ldb: usize,
        beta: f32,
        c: &mut [f32],
        ldc: usize,
    ) -> Result<()> {
        // Integration with optimized BLAS implementation
        // This could use OpenBLAS, Intel MKL, or custom SIMD implementation
        unsafe {
            cblas_sgemm(
                if trans_a { CblasRowMajor } else { CblasNoTrans },
                if trans_b { CblasTrans } else { CblasNoTrans },
                m as i32, n as i32, k as i32,
                alpha,
                a.as_ptr(), lda as i32,
                b.as_ptr(), ldb as i32,
                beta,
                c.as_mut_ptr(), ldc as i32,
            );
        }
        Ok(())
    }
}
```

## Implementation Plan

### Task 1: GEMM-Based Convolution
- [ ] Implement im2col transformation for converting convolution to matrix multiplication
- [ ] Integrate with optimized BLAS library (OpenBLAS or Intel MKL)
- [ ] Add parallel processing for im2col transformation
- [ ] Optimize memory layout and cache usage

### Task 2: Winograd Convolution
- [ ] Implement Winograd F(2x2, 3x3) algorithm for 3x3 kernels
- [ ] Add Winograd F(4x4, 3x3) for larger output tiles
- [ ] Optimize data transformations and minimize temporary allocations
- [ ] Add support for different kernel sizes

### Task 3: FFT-Based Convolution
- [ ] Implement FFT-based convolution for large kernels
- [ ] Add support for complex number operations
- [ ] Optimize for power-of-two input sizes
- [ ] Handle arbitrary input sizes with padding

### Task 4: Strategy Selection and Optimization
- [ ] Implement automatic strategy selection based on problem size
- [ ] Add benchmarking to calibrate selection heuristics
- [ ] Optimize for different hardware configurations
- [ ] Add performance monitoring and profiling

## Testing Strategy

### Performance Tests
```rust
#[bench]
fn bench_conv2d_strategies(b: &mut Bencher) {
    let conv = OptimizedConv2D::new().unwrap();
    let input = vec![1.0f32; 1 * 3 * 224 * 224]; // ImageNet-like input
    let weight = vec![0.1f32; 64 * 3 * 3 * 3];   // 64 3x3 filters
    let mut output = vec![0.0f32; 1 * 64 * 224 * 224];

    let params = Conv2DParams {
        kernel_size: 3,
        stride: 1,
        padding: 1,
    };

    b.iter(|| {
        conv.conv2d(
            &input, &weight, None, &mut output,
            params, (1, 3, 224, 224), (64, 3, 3, 3)
        ).unwrap();
    });
}

#[test]
fn test_conv2d_correctness() {
    let conv = OptimizedConv2D::new().unwrap();

    // Test against reference implementation
    let input = create_test_input();
    let weight = create_test_weight();
    let mut output_optimized = vec![0.0f32; expected_output_size()];
    let mut output_reference = vec![0.0f32; expected_output_size()];

    // Optimized implementation
    conv.conv2d(&input, &weight, None, &mut output_optimized, params, input_dims, weight_dims).unwrap();

    // Reference naive implementation
    conv2d_naive(&input, &weight, None, &mut output_reference, params, input_dims, weight_dims).unwrap();

    // Verify results match within tolerance
    for (opt, ref_val) in output_optimized.iter().zip(output_reference.iter()) {
        assert!((opt - ref_val).abs() < 1e-5, "Optimization changed results");
    }
}
```

## Related Issues/PRs

- Critical for CNN and computer vision model performance
- Related to SIMD optimization and vectorization
- Part of comprehensive kernel optimization initiative

## Acceptance Criteria

- [ ] GEMM-based convolution provides 10x+ performance improvement over naive implementation
- [ ] Winograd convolution works correctly for 3x3 kernels
- [ ] FFT-based convolution handles large kernels efficiently
- [ ] Strategy selection automatically chooses optimal algorithm
- [ ] All optimized implementations produce numerically equivalent results
- [ ] Performance scales appropriately with problem size
- [ ] Memory usage is optimized for different convolution strategies

## Risk Assessment

**Medium-High Risk**: Convolution optimization affects numerical stability and performance characteristics.

**Mitigation Strategies**:
- Implement comprehensive correctness testing against reference implementation
- Add numerical stability validation for different data ranges
- Provide fallback to naive implementation if optimized versions fail
- Implement gradual rollout with performance monitoring
- Add extensive benchmarking to validate performance improvements
